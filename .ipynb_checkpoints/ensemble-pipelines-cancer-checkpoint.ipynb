{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Diagnosis - Ensemble and Pipelines\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "This dataset is called \"Breast cancer wisconsin (diagnostic) dataset\" and it contains 30 features for 569 examples that describe various properties of tumours identified.\n",
    "\n",
    "Some of these features are:\n",
    "\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "\n",
    "- texture (standard deviation of gray-scale values)\n",
    "\n",
    "- perimeter\n",
    "\n",
    "- area\n",
    "\n",
    "- smoothness (local variation in radius lengths)\n",
    "\n",
    "- compactness (perimeter^2 / area - 1.0)\n",
    "\n",
    "- concavity (severity of concave portions of the contour)\n",
    "\n",
    "- concave points (number of concave portions of the contour)\n",
    "\n",
    "- symmetry\n",
    "\n",
    "- fractal dimension (“coastline approximation” - 1)\n",
    "\n",
    "## Classification Task\n",
    "\n",
    "**We use the given information about a tumour to predict whether it is malignant (0) or benign (1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separation into Training/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "X, y = breast_cancer.data, breast_cancer.target\n",
    "### 0 - malignant, 1 - benign\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier and Pipeline Initializations \n",
    "\n",
    "#### Feature Scaling\n",
    "Is done do have all feature vectors in a similar range; is being performed using **StandardScaler**\n",
    "\n",
    "#### Feature Transformers\n",
    "A feature transformer we are using is PCA - Principal Component Analysis - which performs dimensionality reduction.\n",
    "\n",
    "#### Classifiers and Pipelines\n",
    "\n",
    "##### Perceptron\n",
    "The perceptron pipeline uses the Perceptron model with a learning rate of 1.0 after performing feature scaling and dimensionality reduction to 5 features\n",
    "\n",
    "##### Decision Tree\n",
    "The decision tree pipeline uses the Decision Tree learning model with a maximum tree depth of 6 and Gini impurity measurement for Information Gain calculations, after performing feature scaling and dimensionality reduction to 5 features\n",
    "\n",
    "##### SVM\n",
    "The SVM pipeline uses the Support Vector Machine model with RBF kernel after performing feature scaling (no dimensionality reduction here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## transformers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "## classifiers\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "## pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "## cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "## perceptron pipeline\n",
    "perceptron_pipe = make_pipeline(StandardScaler(), PCA(n_components=5), Perceptron(eta0=1.0, random_state=1))\n",
    "\n",
    "## decision tree pipeline\n",
    "tree_pipe = make_pipeline(StandardScaler(), \n",
    "                                PCA(n_components=5), \n",
    "                                DecisionTreeClassifier(max_depth=6, criterion='gini', random_state=1))\n",
    "\n",
    "## SVM pipeline\n",
    "svm_pipe = make_pipeline(StandardScaler(), SVC(kernel='rbf', C=10.0, gamma=0.1, random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Fold Cross Validation\n",
    "\n",
    "Note: I have carried out the cross validation process multiple times to tune some hyperparameters first.\n",
    "\n",
    "It looks like Perceptron pipeline would generalize best to the test set according to 10-fold cross validation, with SVM pipeline coming second, followed by Decision Tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      "Accuracy: 0.97 Stdev: 0.028 [Perceptron]\n",
      "Accuracy: 0.95 Stdev: 0.036 [Decision tree]\n",
      "Accuracy: 0.96 Stdev: 0.039 [SVM]\n"
     ]
    }
   ],
   "source": [
    "## labels of classifiers used\n",
    "clf_labels = ['Perceptron', 'Decision tree', 'SVM']\n",
    "\n",
    "print('10-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([perceptron_pipe, tree_pipe, svm_pipe], clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy')\n",
    "    print(\"Accuracy: \" + str(round(scores.mean(), 2)) + \n",
    "          \" Stdev: \" + str(round(scores.std(), 3)) +\n",
    "          \" [\" + label + \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Ensemble Model\n",
    "\n",
    "Here we use Majority Voting Rule to create an ensemble model.\n",
    "\n",
    "After performing cross validation on the ensemble (along with other pipelines),\n",
    "we see that it's predicted to generalize best to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97 Stdev: 0.028 [Perceptron]\n",
      "Accuracy: 0.95 Stdev: 0.036 [Decision tree]\n",
      "Accuracy: 0.96 Stdev: 0.039 [SVM]\n",
      "Accuracy: 0.98 Stdev: 0.03 [Majority voting]\n"
     ]
    }
   ],
   "source": [
    "## ensemble model\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble_clf = VotingClassifier(estimators=[('p', perceptron_pipe), ('dt', tree_pipe), ('svm', svm_pipe)])\n",
    "\n",
    "clf_labels += ['Majority voting']\n",
    "all_clf = [perceptron_pipe, tree_pipe, svm_pipe, ensemble_clf]\n",
    "\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='accuracy')\n",
    "    print(\"Accuracy: \" + str(round(scores.mean(), 2)) + \n",
    "          \" Stdev: \" + str(round(scores.std(), 3)) +\n",
    "          \" [\" + label + \"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Perceptron------\n",
      "Misclassified test set examples: 9\n",
      "Out of a total of: 171\n",
      "Accuracy: 0.9473684210526315\n",
      "------Decision tree------\n",
      "Misclassified test set examples: 13\n",
      "Out of a total of: 171\n",
      "Accuracy: 0.9239766081871345\n",
      "------SVM------\n",
      "Misclassified test set examples: 10\n",
      "Out of a total of: 171\n",
      "Accuracy: 0.9415204678362573\n",
      "------Majority voting------\n",
      "Misclassified test set examples: 5\n",
      "Out of a total of: 171\n",
      "Accuracy: 0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "## perceptron pipeline final testing\n",
    "\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('------' + label + '------')\n",
    "    print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "    print('Out of a total of:', y_test.shape[0])\n",
    "    print('Accuracy:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Indeed, as predicted by 10-fold cross validation,\n",
    "the Majority Voting Ensemble model performs best on the test set, followed by Perceptron, SVM, and Decision Tree pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
